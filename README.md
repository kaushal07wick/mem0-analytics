# ğŸ§  Mem0 Analytics

> Real-time analytics intelligence for memory-driven AI systems

[![Python](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![PostgreSQL](https://img.shields.io/badge/Postgres-analytics%20backend-blue?logo=postgresql)](https://www.postgresql.org/)
[![PostHog](https://img.shields.io/badge/PostHog-dashboard-orange?logo=posthog)](https://posthog.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](#-contributing)

---

### ğŸ§© Overview

**Mem0 Analytics** provides **observability, telemetry, and performance analytics** for the [Mem0](https://github.com/mem0ai/mem0) ecosystem â€” an intelligent memory layer for LLMs.

It captures **live metrics** from memory operations (`add`, `search`, etc.), aggregates data in **PostgreSQL**, and pushes **real-time KPIs** to **PostHog dashboards**.
Built for **engineers**, **data scientists**, and **infra teams** optimizing RAG and chat pipelines.

---

## ğŸš€ Live Dashboard

ğŸ”— [**View Real-Time Mem0 Dashboard on PostHog â†’**](https://us.posthog.com/shared/0_gFtZ5fE8WhDNVXKlTHh2i4v31uSQ)

**Tracks:**

* âš¡ Latency (avg & P95) by model and provider
* ğŸ§  Embedding, vector, and LLM latency distribution
* ğŸ’¾ Cache effectiveness and token efficiency
* ğŸ’° Cost, token throughput, and reliability index
* ğŸ§© CPU & memory utilization per function

---

## âš™ï¸ Architecture

```mermaid
graph TD
    A[Mem0 Chat / Agent Apps] -->|Analytics wrapper| B[(PostgreSQL)]
    B -->|Aggregates per minute| C[Daemon (Aggregator)]
    C -->|Push batch metrics| D[PostHog Dashboard]
    D --> E[Insights / Alerts / Visuals]
```

**Core Components**

* `analytics.py` â€” instruments Mem0 calls, logs metrics to PostgreSQL
* `daemon.py` â€” aggregates data, computes KPIs, syncs to PostHog
* `schema.sql` â€” defines tables for raw & aggregated metrics

---

## ğŸ“Š Metrics Tracked

| Category                 | Metrics                                                       | Description                         |
| ------------------------ | ------------------------------------------------------------- | ----------------------------------- |
| **Performance**          | `latency_ms`, `latency_p95`, `ttfr_ms`                        | Total, tail, and cold-start latency |
| **Tokens & Cost**        | `prompt_tokens`, `completion_tokens`, `estimated_cost_usd`    | Token usage and per-call cost       |
| **Resource Utilization** | `cpu_percent`, `mem_used_mb`, `disk_read_kb`, `disk_write_kb` | System-level stats                  |
| **Reliability**          | `error_rate`, `reliability_index`                             | Operational stability               |
| **Efficiency**           | `cache_hit_ratio`, `token_efficiency`, `vector_contribution`  | Throughput and cache health         |

---

## ğŸ“ˆ Sample Insights (Live)

* **ğŸš€ smolm2** is **4.7Ã— faster** than gpt-5-nano
* **âš ï¸ gpt-4o-mini** shows **6.9Ã— latency spikes** â€” circuit breaker recommended
* **ğŸ’¾ Cache hit rate <1%** â€” huge optimization opportunity
* **ğŸ“Š Vector stores (Qdrant / ChromaDB)** perform <10 ms, no bottleneck
* **ğŸ§  TTFR <10 ms** â€” zero cold-start overhead

---

## ğŸ”§ Quick Start

```bash
# 1ï¸âƒ£ Clone repo
git clone https://github.com/mem0ai/mem0-analytics.git
cd mem0-analytics

# 2ï¸âƒ£ Configure environment
cp .env.example .env
# Add PG_DSN, POSTHOG_API_KEY, and other variables

# 3ï¸âƒ£ Initialize database
psql -U <user> -d mem0_analytics -f schema.sql

# 4ï¸âƒ£ Run analytics tracker
python analytics.py

# 5ï¸âƒ£ Start the continuous aggregator
python daemon.py
```

---

## ğŸ’» Example Dashboard Visuals

| Metric                     | Visualization | Insight                          |
| -------------------------- | ------------- | -------------------------------- |
| Avg & P95 Latency by Model | Line chart    | Detect tail performance drift    |
| Pipeline Breakdown         | Stacked bar   | Time in embedding â†’ vector â†’ LLM |
| Cache Hit Rate (%)         | Area          | Track caching improvements       |
| Token Usage vs Latency     | Scatter       | Efficiency across models         |
| CPU & Memory by Function   | Bar           | Resource footprint monitoring    |

---

## ğŸ”¬ Engineering Highlights

* Built with **PostgreSQL** + **SQLAlchemy**
* Real-time sync to **PostHog** via batch API
* Clean modular structure (daemon, analytics, schema)
* Configurable via `.env`
* CSV + Parquet data export for offline analysis
* Fully extensible for **custom metrics**

---

## ğŸ§­ Roadmap & Future Scope
## ğŸ§© Integration Roadmap â€” LLMs & Vector Stores

### ğŸ”® Planned LLM Integrations

| Provider         | Model / API                        | Status       | Notes                                                      |
| ---------------- | ---------------------------------- | ------------ | ---------------------------------------------------------- |
| âœ… **OpenAI**     | `gpt-4o-mini`, `gpt-5-nano`        | âœ… Integrated | Fully instrumented, latency & cost tracked                 |
| âœ… **Ollama**     | `smollm2`, `smollm2:135m`          | âœ… Integrated | Local inference, cost-free tracking                        |
| ğŸ”² **Anthropic** | `claude-3-opus`, `claude-3-sonnet` | â³ Planned    | Add API latency & token-level cost                         |
| ğŸ”² **Groq**      | `mixtral`, `llama3-groq`           | â³ Planned    | Measure sub-10ms ultra-low latency benchmarks              |
| ğŸ”² **xAI**       | `Grok-2`                           | â³ Planned    | Integrate via REST, track reliability index                |
| ğŸ”² **Meta**      | `Llama-3.1`, `Llama-4` (local)     | â³ Planned    | Local benchmarking with Ollama + CPU usage metrics         |
| ğŸ”² **Google**    | `Gemini-2`                         | â³ Planned    | Compare cost-to-performance vs OpenAI                      |
| ğŸ”² **DeepSeek**  | `DeepSeek-Coder`, `DeepSeek-Chat`  | â³ Planned    | Token-efficient models to benchmark memory cost efficiency |

---

### ğŸ§  Planned Vector Store Integrations

| Vector Store        | Type           | Status       | Notes                                                    |
| ------------------- | -------------- | ------------ | -------------------------------------------------------- |
| âœ… **Qdrant**        | Remote (Rust)  | âœ… Integrated | Fastest in production (avg <10ms latency)                |
| âœ… **ChromaDB**      | Local (Python) | âœ… Integrated | Ideal for lightweight dev workloads                      |
| ğŸ”² **Pinecone**     | Cloud          | â³ Planned    | Enterprise-grade, multi-tenant metrics                   |
| ğŸ”² **Weaviate**     | Cloud/Local    | â³ Planned    | Measure hybrid query latency                             |
| ğŸ”² **Milvus**       | Local/Cluster  | â³ Planned    | Benchmark with high vector throughput                    |
| ğŸ”² **Redis Vector** | In-memory      | â³ Planned    | Low-latency cache-style retrieval benchmarking           |
| ğŸ”² **LanceDB**      | Local          | â³ Planned    | Evaluate performance with Arrow-based storage            |
| ğŸ”² **FAISS**        | Local          | â³ Planned    | Offline RAG experimentation and embedding cache baseline |

---

### ğŸ§° Additional Infrastructure Targets

| Category                           | Tool / Layer                        | Purpose |
| ---------------------------------- | ----------------------------------- | ------- |
| ğŸ”² **Prometheus + Grafana**        | Real-time resource observability    |         |
| ğŸ”² **Kubernetes Metrics Exporter** | Track memory, CPU, I/O per Mem0 pod |         |
| ğŸ”² **S3 + MinIO Data Lake**        | Long-term metrics archival          |         |
| ğŸ”² **Airflow / Prefect**           | Scheduled metric aggregation jobs   |         |
| ğŸ”² **OpenTelemetry**               | Unified tracing for RAG workflows   |         |



## ğŸ¤ Contributing

Pull requests are welcome!
If youâ€™d like to add new metrics, providers, or integrations, open an issue or start a discussion.

```bash
git checkout -b feature/add-groq-support
git commit -am "Add Groq inference metrics"
git push origin feature/add-groq-support
```

## ğŸ“œ License

Released under the **MIT License**.
See [`LICENSE`](./LICENSE) for details.


