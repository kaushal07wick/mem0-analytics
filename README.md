# ğŸ§  Mem0 Analytics

> **Telemetry and performance intelligence for memory-driven AI systems.**
> One install â€” full visibility into how your Mem0 stack performs.

[![PyPI](https://img.shields.io/pypi/v/mem0-analytics.svg?color=0078D7)](https://pypi.org/project/mem0-analytics/)
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![SQLite](https://img.shields.io/badge/Local%20Metrics-SQLite-lightgrey?logo=sqlite)](https://sqlite.org/)
[![PostHog](https://img.shields.io/badge/Cloud%20Dashboards-PostHog-orange?logo=posthog)](https://posthog.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ§© What It Is

**Mem0 Analytics** is the **built-in monitoring and observability layer** for the [Mem0](https://github.com/mem0ai/mem0) framework.
It measures, aggregates, and visualizes the complete lifecycle of memory interactions â€” from LLM calls to vector operations â€” with **no manual setup or instrumentation required**.

Once installed, it automatically:

* Captures latency, token usage, cache efficiency, and system metrics
* Aggregates performance data every 60 seconds
* Displays results through a **real-time terminal dashboard**
* Optionally syncs to **PostHog** for team dashboards

---

## âš¡ Quick Start

Install directly from PyPI:

```bash
pip install mem0-analytics
```

Then just use Mem0 as usual â€” analytics activates automatically.

To open the **live dashboard**, run:

```bash
mem0-dashboard
```

Metrics are stored locally at:

```
~/.mem0_metrics.db
```

ğŸ›¢ï¸ To see the db, open the SQLite shell
```bash
sqlite3 ~/.mem0_metrics.db
```


ğŸ“Š List all tables
```bash
.tables
```

You should see something like:
```bash
mem0_met      mem0_kpi
```

View the schema of a specific table
```bash
.schema mem0_kpi
```

or for the raw metrics:
```bash
.schema mem0_met
```

Preview table contents
```bash
SELECT * FROM mem0_kpi LIMIT 10;
```

See table info (columns and types)
```bash
PRAGMA table_info(mem0_kpi);
```

---

## ğŸ“Š What It Tracks

| Category         | Metrics                                     | Description                            |
| ---------------- | ------------------------------------------- | -------------------------------------- |
| **Performance**  | `avg_latency_ms`, `latency_p95`, `ttfr_ms`  | Average, tail, and cold-start latency  |
| **Embeddings**   | `avg_embed_latency`                         | Mean embedding generation time         |
| **Vector Store** | `avg_vector_latency`, `cache_effectiveness` | Query efficiency and cache utilization |
| **System**       | `cpu_percent`, `mem_used_mb`                | Process-level system footprint         |
| **Reliability**  | `success_rate`, `error_rate`                | Operation health and stability         |

---

## ğŸ–¥ Local Dashboard

![terminal](./static/terminal.png)

A high-frequency dashboard rendered with [`rich`](https://github.com/Textualize/rich), showing:

* Latency (mean and P95) by function
* Embedder and vector database performance
* Cache efficiency and request success rate
* Time-to-First-Response (TTFR)
* Live stability and health indicators

No external services. Runs fully offline.

---

## â˜ï¸ Cloud Integration (Optional)

For centralized analytics or multi-agent visibility:

```bash
export POSTHOG_API_KEY=<your_key>
export POSTHOG_HOST=https://app.posthog.com
```

The local aggregator automatically batches KPIs and publishes them to PostHog every 60 seconds.

---

## ğŸ§± Architecture

```
Mem0 (LLM, Vector Store, Embedder)
   â”‚
   â”œâ”€â”€ analytics.py  â†’ auto-captures runtime metrics
   â”‚
   â”œâ”€â”€ ~/.mem0_metrics.db  â†’ local SQLite telemetry store
   â”‚
   â”œâ”€â”€ dashboard.py  â†’ live Rich terminal visualization
   â”‚
   â””â”€â”€ (optional) PostHog sync â†’ team dashboards
```

**Local-first by default** â€” privacy-safe, transparent, and extensible.

---

## ğŸ”§ Supported Ecosystem

Mem0 Analytics automatically works across all Mem0 integrations:

| Layer             | Supported Backends                                                                                    |
| ----------------- | ----------------------------------------------------------------------------------------------------- |
| **LLMs**          | OpenAI (`gpt-5-nano`, `gpt-4o-mini`), Ollama (`smollm2`), Claude, Gemini, LLaMA, DeepSeek, Groq, etc. |
| **Vector Stores** | Qdrant, ChromaDB, Weaviate, FAISS, Pinecone, Milvus, Redis, LanceDB                                   |
| **Embedders**     | OpenAI, Ollama, Hugging Face, Instructor, BGE, Sentence Transformers                                  |

No adapters, no config. If it runs on Mem0 â€” itâ€™s tracked.

---

## ğŸ§  Why It Exists

Monitoring LLM pipelines shouldnâ€™t need Grafana, SQL schemas, or complex telemetry setups.
**Mem0 Analytics** makes performance **transparent** â€” giving developers instant insight into how memory operations behave, degrade, and optimize over time.

---

## ğŸ”¬ Highlights

* âš™ï¸ Zero-config integration with Mem0
* ğŸª¶ Lightweight â€” <1 ms overhead per call
* ğŸ“¦ SQLite for local metrics
* ğŸ“Š Real-time Rich dashboard
* â˜ï¸ PostHog cloud mode for teams
* ğŸ” Rolling aggregation of KPIs every minute
* ğŸ§© Pluggable design â€” supports any backend

---

## ğŸ§­ Roadmap

* [x] Local SQLite metrics engine
* [x] Live terminal dashboard
* [x] PostHog sync
* [x] Token & cost analysis
* [x] Anomaly alerts (p95, cache, TTFR)
* [ ] Prometheus exporter
* [ ] Multi-agent benchmarking

---

## ğŸ¤ Contributing

Pull requests are open.
Extend metric types, add providers, or improve visualizations.

---

## ğŸ“œ License

Licensed under the **MIT License**.
See [`LICENSE`](./LICENSE) for details.
